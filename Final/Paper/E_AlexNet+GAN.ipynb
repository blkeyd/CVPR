{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxSJxlMjEoU9m2YrmHWtVf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blkeyd/CVPR/blob/main/Final/Paper/E_AlexNet%2BGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enhanced ALexNet + GAN"
      ],
      "metadata": {
        "id": "sUrmUk4PWPcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "4DS1SSK-WIu8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tZtd2S9UWFXD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
        "from PIL import Image\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive"
      ],
      "metadata": {
        "id": "QuxzEpmKWa3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRvdDinJWcll",
        "outputId": "90f74b68-412d-41af-f0c7-e537d5a4f019"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Device"
      ],
      "metadata": {
        "id": "_fdCTXVkWXZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6Gxs_jIWaA_",
        "outputId": "68362649-5897-4570-e2d9-ece54217cdbd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paths"
      ],
      "metadata": {
        "id": "EILleQyDWeHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_fire_dir = \"/content/drive/MyDrive/fire_dataset_split/train/fire\"\n",
        "gan_fire_dir  = \"/content/drive/MyDrive/gan_generated_fire\"\n",
        "nofire_dir    = \"/content/drive/MyDrive/fire_dataset_split/train/nofire\"\n",
        "val_dir       = \"/content/drive/MyDrive/fire_dataset_split/val\"\n",
        "test_dir      = \"/content/drive/MyDrive/fire_dataset_split/test\""
      ],
      "metadata": {
        "id": "m25qIVT-WfQB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms"
      ],
      "metadata": {
        "id": "TQBInk1tWgpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "GOWDimaHWi3j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Dataset for GAN images"
      ],
      "metadata": {
        "id": "EaQqkaXJWkjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GANFireDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.transform = transform\n",
        "        self.images = [os.path.join(folder_path,f)\n",
        "                       for f in os.listdir(folder_path) if f.endswith(\".png\")]\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.images[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = 0  # fire class\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "kWZ6EUuNWnTx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Datasets"
      ],
      "metadata": {
        "id": "DobCWj6GWpKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Real fire images\n",
        "real_fire_dataset = datasets.ImageFolder(os.path.dirname(real_fire_dir), transform=transform)\n",
        "fire_class_index = real_fire_dataset.class_to_idx['fire']\n",
        "real_fire_dataset.samples = [s for s in real_fire_dataset.samples if s[1]==fire_class_index]\n",
        "\n",
        "# GAN fire images\n",
        "gan_fire_dataset = GANFireDataset(gan_fire_dir, transform=transform)\n",
        "\n",
        "# No-fire images\n",
        "nofire_dataset = datasets.ImageFolder(os.path.dirname(nofire_dir), transform=transform)\n",
        "nofire_class_index = nofire_dataset.class_to_idx['nofire']\n",
        "nofire_dataset.samples = [s for s in nofire_dataset.samples if s[1]==nofire_class_index]\n",
        "\n",
        "# Merge datasets\n",
        "train_dataset = ConcatDataset([real_fire_dataset, gan_fire_dataset, nofire_dataset])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Validation & Test datasets\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "D3f7_jGRWsgd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SE Block"
      ],
      "metadata": {
        "id": "JJo8q_NdWtDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
        "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = nn.functional.adaptive_avg_pool2d(x,1).view(b,c)\n",
        "        y = nn.functional.relu(self.fc1(y))\n",
        "        y = torch.sigmoid(self.fc2(y)).view(b,c,1,1)\n",
        "        return x * y"
      ],
      "metadata": {
        "id": "ynI_vJ6sWvq5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enhanced AlexNet"
      ],
      "metadata": {
        "id": "uNtV0oUOWwSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedAlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(EnhancedAlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            SEBlock(384),\n",
        "\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256*6*6, 4096),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-h02MA0OWzGg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Model"
      ],
      "metadata": {
        "id": "-Qc5rMdKW2Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = EnhancedAlexNet(num_classes=2).to(device)"
      ],
      "metadata": {
        "id": "gP6YXnSIW4SV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss and Optimizer"
      ],
      "metadata": {
        "id": "crTn0ZqJW5v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "UTsJoXpiW7hz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Function"
      ],
      "metadata": {
        "id": "2-DBaxUGW88h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "        train_acc = 100*correct/total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs, labels = imgs.to(device), labels.to(device)\n",
        "                outputs = model(imgs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "        val_acc = 100*val_correct/val_total\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] Train Acc: {train_acc:.2f}%  Val Acc: {val_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "VLWN2immW_O9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation function"
      ],
      "metadata": {
        "id": "DCikNWmmXCaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_labels, all_preds = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            _, preds = torch.max(outputs,1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(all_labels, all_preds))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=['fire','nofire']))"
      ],
      "metadata": {
        "id": "G9n9-2nXXEy3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Evaluate"
      ],
      "metadata": {
        "id": "jeztXuXCXGRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, epochs=10)\n",
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8xOITzKXKO2",
        "outputId": "c484611f-573b-453e-80b9-ab16f277c388"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Train Acc: 91.65%  Val Acc: 91.95%\n",
            "Epoch [2/10] Train Acc: 96.74%  Val Acc: 93.29%\n",
            "Epoch [3/10] Train Acc: 98.50%  Val Acc: 95.97%\n",
            "Epoch [4/10] Train Acc: 97.41%  Val Acc: 93.29%\n",
            "Epoch [5/10] Train Acc: 98.50%  Val Acc: 93.96%\n",
            "Epoch [6/10] Train Acc: 98.08%  Val Acc: 92.62%\n",
            "Epoch [7/10] Train Acc: 98.66%  Val Acc: 95.30%\n",
            "Epoch [8/10] Train Acc: 98.33%  Val Acc: 93.96%\n",
            "Epoch [9/10] Train Acc: 98.66%  Val Acc: 96.64%\n",
            "Epoch [10/10] Train Acc: 99.08%  Val Acc: 94.63%\n",
            "Confusion Matrix:\n",
            " [[110   4]\n",
            " [  2  36]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        fire       0.98      0.96      0.97       114\n",
            "      nofire       0.90      0.95      0.92        38\n",
            "\n",
            "    accuracy                           0.96       152\n",
            "   macro avg       0.94      0.96      0.95       152\n",
            "weighted avg       0.96      0.96      0.96       152\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model"
      ],
      "metadata": {
        "id": "ptFEFXQiXLgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/enhanced_alexnet_gan_fire.pth\")\n",
        "print(\"Enhanced AlexNet + GAN model saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBjKbjDdXN6o",
        "outputId": "02148222-6edb-48d1-b576-554f138f1c99"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced AlexNet + GAN model saved.\n"
          ]
        }
      ]
    }
  ]
}